{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T11:40:55.850706Z",
     "start_time": "2023-05-22T11:40:55.833163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set DMZ working directory, all paths will be relative (downstream) to this directory\n",
    "\n",
    "import os\n",
    "\n",
    "working_directory = \"/Users/christelvanharen/Documents/StageRadboud/isatools/TWOCdemonstrator/data/ISA_test\"  #TODO: parameterize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T11:40:55.858884Z",
     "start_time": "2023-05-22T11:40:55.837704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isa-to-rdfs.py',\n",
       " 'TWOC_create_isa.ipynb',\n",
       " 'README.md',\n",
       " '.ipynb_checkpoints',\n",
       " 'TWOC_test_isa.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T11:40:56.106615Z",
     "start_time": "2023-05-22T11:40:55.842919Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE-ID</th>\n",
       "      <th>FILENAME_fwd</th>\n",
       "      <th>FILENAME_rev</th>\n",
       "      <th>SUBJECT-ID</th>\n",
       "      <th>RUN</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE_(Y)</th>\n",
       "      <th>HEIGHT_(CM)</th>\n",
       "      <th>WEIGHT_(KG)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIETARY_SUPPLEMENTS</th>\n",
       "      <th>PROBIOTICS</th>\n",
       "      <th>DIET</th>\n",
       "      <th>DONATATION</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>RANKSTAT_GENDER</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample028</td>\n",
       "      <td>sample028_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample028_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10038</td>\n",
       "      <td>run_6</td>\n",
       "      <td>M</td>\n",
       "      <td>33</td>\n",
       "      <td>180,34</td>\n",
       "      <td>80,38</td>\n",
       "      <td>24,73</td>\n",
       "      <td>Vitamin B12 and D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample031</td>\n",
       "      <td>sample031_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample031_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10038</td>\n",
       "      <td>run_6</td>\n",
       "      <td>M</td>\n",
       "      <td>33</td>\n",
       "      <td>180,34</td>\n",
       "      <td>80,38</td>\n",
       "      <td>24,73</td>\n",
       "      <td>Vitamin B12 and D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample118</td>\n",
       "      <td>sample118_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample118_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10038</td>\n",
       "      <td>run_10</td>\n",
       "      <td>M</td>\n",
       "      <td>33</td>\n",
       "      <td>182,9</td>\n",
       "      <td>72,35</td>\n",
       "      <td>24,73</td>\n",
       "      <td>Vitamin B12 and D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample121</td>\n",
       "      <td>sample121_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample121_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10042</td>\n",
       "      <td>run_10</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>182,9</td>\n",
       "      <td>72,35</td>\n",
       "      <td>21,51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yakult probiotic drink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample126</td>\n",
       "      <td>sample126_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample126_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10048</td>\n",
       "      <td>run_10</td>\n",
       "      <td>M</td>\n",
       "      <td>36</td>\n",
       "      <td>182,9</td>\n",
       "      <td>72,35</td>\n",
       "      <td>22,2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>sample184</td>\n",
       "      <td>sample184_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample184_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10911</td>\n",
       "      <td>run_11</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>177,8</td>\n",
       "      <td>87,14</td>\n",
       "      <td>21,22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>sample187</td>\n",
       "      <td>sample187_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample187_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10959</td>\n",
       "      <td>run_11</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>188,21</td>\n",
       "      <td>79,15</td>\n",
       "      <td>17,08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample188</td>\n",
       "      <td>sample188_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample188_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-10959</td>\n",
       "      <td>run_11</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>188,21</td>\n",
       "      <td>79,15</td>\n",
       "      <td>17,08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample189</td>\n",
       "      <td>sample189_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample189_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-11094</td>\n",
       "      <td>run_11</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>173,36</td>\n",
       "      <td>90,4</td>\n",
       "      <td>26,37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample190</td>\n",
       "      <td>sample190_S001_L001_R1_001.fastq.gz</td>\n",
       "      <td>sample190_S001_L001_R2_001.fastq.gz</td>\n",
       "      <td>FT-11094</td>\n",
       "      <td>run_11</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>173,36</td>\n",
       "      <td>90,4</td>\n",
       "      <td>26,37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAMPLE-ID                         FILENAME_fwd  \\\n",
       "0    sample028  sample028_S001_L001_R1_001.fastq.gz   \n",
       "1    sample031  sample031_S001_L001_R1_001.fastq.gz   \n",
       "2    sample118  sample118_S001_L001_R1_001.fastq.gz   \n",
       "3    sample121  sample121_S001_L001_R1_001.fastq.gz   \n",
       "4    sample126  sample126_S001_L001_R1_001.fastq.gz   \n",
       "..         ...                                  ...   \n",
       "118  sample184  sample184_S001_L001_R1_001.fastq.gz   \n",
       "119  sample187  sample187_S001_L001_R1_001.fastq.gz   \n",
       "120  sample188  sample188_S001_L001_R1_001.fastq.gz   \n",
       "121  sample189  sample189_S001_L001_R1_001.fastq.gz   \n",
       "122  sample190  sample190_S001_L001_R1_001.fastq.gz   \n",
       "\n",
       "                            FILENAME_rev SUBJECT-ID     RUN GENDER  AGE_(Y)  \\\n",
       "0    sample028_S001_L001_R2_001.fastq.gz   FT-10038   run_6      M       33   \n",
       "1    sample031_S001_L001_R2_001.fastq.gz   FT-10038   run_6      M       33   \n",
       "2    sample118_S001_L001_R2_001.fastq.gz   FT-10038  run_10      M       33   \n",
       "3    sample121_S001_L001_R2_001.fastq.gz   FT-10042  run_10      M       23   \n",
       "4    sample126_S001_L001_R2_001.fastq.gz   FT-10048  run_10      M       36   \n",
       "..                                   ...        ...     ...    ...      ...   \n",
       "118  sample184_S001_L001_R2_001.fastq.gz   FT-10911  run_11      M       24   \n",
       "119  sample187_S001_L001_R2_001.fastq.gz   FT-10959  run_11      M       35   \n",
       "120  sample188_S001_L001_R2_001.fastq.gz   FT-10959  run_11      M       35   \n",
       "121  sample189_S001_L001_R2_001.fastq.gz   FT-11094  run_11      F       19   \n",
       "122  sample190_S001_L001_R2_001.fastq.gz   FT-11094  run_11      F       19   \n",
       "\n",
       "    HEIGHT_(CM) WEIGHT_(KG)    BMI DIETARY_SUPPLEMENTS  \\\n",
       "0        180,34       80,38  24,73   Vitamin B12 and D   \n",
       "1        180,34       80,38  24,73   Vitamin B12 and D   \n",
       "2         182,9       72,35  24,73   Vitamin B12 and D   \n",
       "3         182,9       72,35  21,51                 NaN   \n",
       "4         182,9       72,35   22,2                 NaN   \n",
       "..          ...         ...    ...                 ...   \n",
       "118       177,8       87,14  21,22                 NaN   \n",
       "119      188,21       79,15  17,08                 NaN   \n",
       "120      188,21       79,15  17,08                 NaN   \n",
       "121      173,36        90,4  26,37                 NaN   \n",
       "122      173,36        90,4  26,37                 NaN   \n",
       "\n",
       "                 PROBIOTICS        DIET DONATATION SUFFIX  RANKSTAT_GENDER  \\\n",
       "0                       NaN  Vegetarian         AF    NaN              NaN   \n",
       "1                       NaN  Vegetarian         AS    NaN              NaN   \n",
       "2                       NaN  Vegetarian         BI    NaN              NaN   \n",
       "3    Yakult probiotic drink         NaN         BH    NaN              NaN   \n",
       "4                       NaN         NaN         AM    NaN              NaN   \n",
       "..                      ...         ...        ...    ...              ...   \n",
       "118                     NaN         NaN         BI    NaN              NaN   \n",
       "119                     NaN         NaN         BI    NaN              NaN   \n",
       "120                     NaN         NaN         AI    NaN              NaN   \n",
       "121                     NaN         NaN         BI    NaN              NaN   \n",
       "122                     NaN         NaN         BK    NaN              NaN   \n",
       "\n",
       "     DESCRIPTION  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "..           ...  \n",
       "118          NaN  \n",
       "119          NaN  \n",
       "120          NaN  \n",
       "121          NaN  \n",
       "122          NaN  \n",
       "\n",
       "[123 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Patient Metadata\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "patient_metadata = pd.read_csv('/Users/christelvanharen/Documents/StageRadboud/isatools/TWOCdemonstrator/data/ISA_test/metadata.tsv', sep='\\t')\n",
    "patient_metadata.columns = patient_metadata.columns.str.replace(' ', '_', regex=True)\n",
    "patient_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T11:40:59.889951Z",
     "start_time": "2023-05-22T11:40:59.866665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set Sample IDs to strings (some control samples are integers)\n",
    "patient_metadata['SAMPLE-ID'] = patient_metadata['SAMPLE-ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:19:43.969747Z",
     "start_time": "2023-05-11T09:19:42.140988Z"
    }
   },
   "outputs": [],
   "source": [
    "from isatools.model import *\n",
    "\n",
    "ontologies = {\n",
    "    \"CHEBI\": OntologySource(\n",
    "        name = \"CHEBI - Chemical Entities of Biological Interest\", \n",
    "        file = \"http://purl.obolibrary.org/obo/chebi.owl\",\n",
    "        description = \"A structured classification of molecular entities of biological interest focusing on 'small' chemical compounds.\"), \n",
    "    \"CHMO\": OntologySource(\n",
    "        name = \"CHMO - Chemical Methods Ontology\", \n",
    "        file = \"http://purl.obolibrary.org/obo/chmo.owl\",\n",
    "        description = \"CHMO, the chemical methods ontology, describes methods used to collect data in chemical experiments, such as mass spectrometry and electron microscopy prepare and separate material for further analysis, such as sample ionisation, chromatography, and electrophoresis synthesise materials, such as epitaxy and continuous vapour deposition It also describes the instruments used in these experiments, such as mass spectrometers and chromatography columns. It is intended to be complementary to the Ontology for Biomedical Investigations (OBI).\"), \n",
    "    \"COVOC\": OntologySource(\n",
    "        name = \"CoVoc Coronavirus Vocabulary\",\n",
    "        file = \"http://purl.obolibrary.org/obo/covoc.owl\",\n",
    "        description = \"The COVID-19 Vocabulary (COVoc) is an ontology containing terms related to the research of the COVID-19 pandemic. This includes host organisms, pathogenicity, gene and gene products, barrier gestures, treatments and more.\"),  \n",
    "    \"CRO\": OntologySource(\n",
    "        # The Contributor Role Ontology (CRO) is an extension of the CASRAI Contributor Roles Taxonomy (CRediT) and replaces the former Contribution Ontology.\n",
    "        name = \"CRO - Contributor Role Ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/cro.owl\",\n",
    "        description = \"A classification of the diverse roles performed in the work leading to a published research output in the sciences. Its purpose to provide transparency in contributions to scholarly published work, to enable improved systems of attribution, credit, and accountability.\"),\n",
    "    \"EDAM\": OntologySource(\n",
    "        name = \"EDAM - EMBRACE Data and Methods\",\n",
    "        file = \"http://edamontology.org/EDAM.owl\",\n",
    "        description = \"Bioinformatics operations, data types, formats, identifiers and topics\"),  \n",
    "    \"EFO\": OntologySource(\n",
    "        name = \"EFO - Experimental Factor Ontology\", \n",
    "        file = \"http://www.ebi.ac.uk/efo/efo.owl\",\n",
    "        description = \"The Experimental Factor Ontology (EFO) provides a systematic description of many experimental variables available in EBI databases, and for external projects such as the NHGRI GWAS catalogue. It combines parts of several biological ontologies, such as anatomy, disease and chemical compounds. The scope of EFO is to support the annotation, analysis and visualization of data handled by many groups at the EBI and as the core ontology for OpenTargets.org\"), \n",
    "    \"ExO\": OntologySource(\n",
    "        name = \"ExO - Exposure ontology\", \n",
    "        file = \"http://purl.obolibrary.org/obo/exo.owl\",\n",
    "        description = \"ExO is intended to bridge the gap between exposure science and diverse environmental health disciplines including toxicology, epidemiology, disease surveillance, and epigenetics.\"), \n",
    "    \"GECKO\": OntologySource(\n",
    "        name = \"GECKO - Genomics Cohorts Knowledge Ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/gecko.owl\",\n",
    "        description = \"An ontology to represent genomics cohort attributes.\"),\n",
    "    \"GSSO\": OntologySource(\n",
    "        name = \"GSSO - the Gender, Sex, and Sexual Orientation ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/gsso.owl\",\n",
    "        description = \"GSSO is the Gender, Sex, and Sex Orientation ontology, including terms related to gender identity and expression, sexual and romantic identity and orientation, and sexual and reproductive behavior.\"),\n",
    "    \"HP\": OntologySource(\n",
    "        name = \"HP - Human Phenotype Ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/hp.owl\",\n",
    "        description = \"The Human Phenotype Ontology (HPO) provides a standardized vocabulary of phenotypic abnormalities and clinical features encountered in human disease.\"),\n",
    "    \"MI\": OntologySource(\n",
    "        name = \"MI - Molecular Interactions Controlled Vocabulary\", \n",
    "        file = \"http://purl.obolibrary.org/obo/mi.owl\",\n",
    "        description = \"A structured controlled vocabulary for the annotation of experiments concerned with protein-protein interactions.\"),\n",
    "    \"MS\": OntologySource(\n",
    "        name = \"MS - Mass spectrometry ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/ms.owl\",\n",
    "        description = \"A structured controlled vocabulary for the annotation of experiments concerned with proteomics mass spectrometry.\"),\n",
    "    \"MSIO\": OntologySource(\n",
    "        name = \"MS - Mass spectrometry ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/msio.owl\",\n",
    "        description = \"MSIO aims to provide a single point of entry to support semantic markup of experiments making use of NMR and MS techniques to identify, measure and quantify small molecules known as metabolites. MSIO covers metabolite profiling, targeted or undertargeted, tracer based applications. MSIO reuses a number of resources such as CHEBI, DUO, NMRCV, OBI, and STATO.\"),\n",
    "    \"NCBITAXON\": OntologySource(\n",
    "        name = \"NCBI organismal classification\", \n",
    "        file = \"http://purl.obolibrary.org/obo/ncbitaxon.owl\",\n",
    "        description = \"An ontology representation of the NCBI organismal taxonomy\"),\n",
    "    \"NCIT\": OntologySource(\n",
    "        name = \"NCI Thesaurus OBO Edition\", \n",
    "        file = \"http://purl.obolibrary.org/obo/ncit.owl\",\n",
    "        description = \"The NCIt OBO Edition project aims to increase integration of the NCIt with OBO Library ontologies. NCIt is a reference terminology that includes broad coverage of the cancer domain, including cancer related diseases, findings and abnormalities. NCIt OBO Edition releases should be considered experimental.\"),\n",
    "    \"NGBO\": OntologySource(\n",
    "        name = \"Next generation biobanking ontology (NGBO).\", \n",
    "        file = \"http://purl.obolibrary.org/obo/obi.owl\",\n",
    "        description = \"Next Generation Biobanking Ontology (NGBO) is an open application ontology representing contextual data about omics digital assets in biobank. The ontology focuses on capturing the information about three main activities: wet bench analysis used to generate omics data, bioinformatics analysis used to analyze and interpret data, and data management.\"),\n",
    "    \"OBI\": OntologySource(\n",
    "        name = \"OBI - Ontology for Biomedical Investigations\", \n",
    "        file = \"http://purl.obolibrary.org/obo/ngbo.owl \",\n",
    "        description = \"An integrated ontology for the description of life-science and clinical investigations\"),\n",
    "    \"OMIABIS\": OntologySource(\n",
    "        name = \"Ontologized MIABIS\", \n",
    "        file = \"http://purl.obolibrary.org/obo/omiabis.owl\",\n",
    "        description = \"An ontological version of MIABIS (Minimum Information About BIobank data Sharing)\"),\n",
    "    \"OMIT\": OntologySource(\n",
    "        name = \"Ontology for MIRNA Target\", \n",
    "        file = \"http://purl.obolibrary.org/obo/omit.owl\",\n",
    "        description = \"Ontology to establish data exchange standards and common data elements in the microRNA (miR) domain.\"),       \n",
    "    \"PRIDE\": OntologySource(\n",
    "        name = \"PRIDE Controlled Vocabulary\",\n",
    "        file = \"http://purl.obolibrary.org/obo/pride_cv.obo\",\n",
    "        description = \"The PRIDE PRoteomics IDEntifications (PRIDE) database is a centralized, standards compliant, public data repository for proteomics data, including protein and peptide identifications, post-translational modifications and supporting spectral evidence.\"),\n",
    "    \"SO\": OntologySource(\n",
    "        name = \"Sequence types and features ontology\", \n",
    "        file = \"http://purl.obolibrary.org/obo/so.owl \",\n",
    "        description = \"A structured controlled vocabulary for sequence annotation, for the exchange of annotation data and for the description of sequence objects in databases.\"),\n",
    "    \"STATO\": OntologySource(\n",
    "        name = \"STATO: the statistical methods ontology\", \n",
    "        file = \"http://purl.obolibrary.org/obo/stato.owl \",\n",
    "        description = \"STATO is the statistical methods ontology. It contains concepts and properties related to statistical methods, probability distributions and other concepts related to statistical analysis, including relationships to study designs and plots. \"),\n",
    "    \"UBERON\": OntologySource(\n",
    "        name = \"Uber-anatomy ontology\",\n",
    "        file = \"http://purl.obolibrary.org/obo/uberon.owl\",\n",
    "        description = \"Uberon is an integrated cross-species anatomy ontology representing a variety of entities classified according to traditional anatomical criteria such as structure, function and developmental lineage. The ontology includes comprehensive relationships to taxon-specific anatomical ontologies, allowing integration of functional, phenotype and expression data.\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:19:47.429639Z",
     "start_time": "2023-05-11T09:19:47.424446Z"
    }
   },
   "outputs": [],
   "source": [
    "investigation = Investigation(\n",
    "    filename = \"i_investigation.txt\", \n",
    "    identifier = \"https://doi.org/10.1186/s13104-021-05520-z\", \n",
    "    title = \"16S rRNA sequencing of samples from universal stool bank donors.\",\n",
    "    description = \"Universal stool banks provide stool to physicians for use in treating recurrent Clostridioides difficile infection via fecal microbiota transplantation. Stool donors providing the material are rigorously screened for diseases and disorders with a potential microbiome etiology, and they are likely healthier than the controls in most microbiome datasets. 16S rRNA sequencing was performed on samples from a selection of stool donors at a large stool bank, OpenBiome, to characterize their gut microbial community and to compare samples across different timepoints and sequencing runs.\",\n",
    "    submission_date = \"\",\n",
    "    public_release_date = \"2021-03-23\",\n",
    "    ontology_source_references = [o for o in ontologies.values()],\n",
    "     publications = [\n",
    "        Publication(doi=\"https://doi.org/10.1186/s13104-021-05520-z\", \n",
    "                    title='16S rRNA sequencing of samples from universal stool bank donors.',\n",
    "                    status=OntologyAnnotation(\n",
    "                                term=\"preprint\",\n",
    "                                term_source= ontologies[\"EFO\"],\n",
    "                                term_accession=\"http://www.ebi.ac.uk/efo/EFO_0010558\"),\n",
    "                    author_list=\"Marina Santiago, Scott W. Olesen\")],\n",
    "    \n",
    "    contacts = [\n",
    "        Person(\n",
    "            last_name = \"Olesen\", \n",
    "            first_name = \"Scott\",\n",
    "            mid_initials = \"W.\",\n",
    "            affiliation = \"OpenBiome, 2067 Massachusetts Ave, Cambridge, MA, 02140, USA\",\n",
    "            email = \"solesen@openbiome.org\",\n",
    "            address = \"https://openbiome.org\",\n",
    "            roles = [\n",
    "                OntologyAnnotation(\n",
    "                    term = \"project management role\",\n",
    "                    term_source = ontologies[\"CRO\"], \n",
    "                    term_accession =\"http://purl.obolibrary.org/obo/CRO_0000065\")])],\n",
    "    studies = None,\n",
    "    comments = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:19:49.831565Z",
     "start_time": "2023-05-11T09:19:49.823319Z"
    }
   },
   "outputs": [],
   "source": [
    "cohort_study = Study(\n",
    "    filename = \"s_study.txt\", \n",
    "    identifier = \"https://doi.org/10.1186/s13104-021-05520-z\", \n",
    "    title = \"16S rRNA sequencing of samples from universal stool bank donors.\",\n",
    "    description = \"Universal stool banks provide stool to physicians for use in treating recurrent Clostridioides difficile infection via fecal microbiota transplantation. Stool donors providing the material are rigorously screened for diseases and disorders with a potential microbiome etiology, and they are likely healthier than the controls in most microbiome datasets. 16S rRNA sequencing was performed on samples from a selection of stool donors at a large stool bank, OpenBiome, to characterize their gut microbial community and to compare samples across different timepoints and sequencing runs.\", \n",
    "    submission_date = \"\", \n",
    "    public_release_date = \"2021-03-23\",\n",
    "    contacts = [\n",
    "        Person(\n",
    "            last_name = \"Olesen\", \n",
    "            first_name = \"Scott\",\n",
    "            mid_initials = \"W.\",\n",
    "            affiliation = \"OpenBiome, 2067 Massachusetts Ave, Cambridge, MA, 02140, USA\",\n",
    "            roles = [\n",
    "                OntologyAnnotation(\n",
    "                    term = \"author role\",\n",
    "                    term_source = ontologies[\"CRO\"], \n",
    "                    term_accession =\"http://purl.obolibrary.org/obo/CRO_0000001\")]),\n",
    "        Person(\n",
    "            last_name = \"Santiago\", \n",
    "            first_name = \"Marina\",\n",
    "            # mid_initials = \"\",\n",
    "            affiliation = \"OpenBiome, 2067 Massachusetts Ave, Cambridge, MA, 02140, USA\",\n",
    "            roles = [\n",
    "                OntologyAnnotation(\n",
    "                    term = \"author role\",\n",
    "                    term_source = ontologies[\"CRO\"], \n",
    "                    term_accession =\"http://purl.obolibrary.org/obo/CRO_0000001\")])],\n",
    "    \n",
    "    # not sure\n",
    "    design_descriptors = [\n",
    "        OntologyAnnotation(\n",
    "                term = \"Multi-omics study\",\n",
    "                term_source = ontologies[\"PRIDE\"],\n",
    "                term_accession = \"http://purl.obolibrary.org/obo/PRIDE_0000461\"),\n",
    "        ],\n",
    "    \n",
    "    publications = [\n",
    "        Publication(doi=\"https://doi.org/10.1186/s13104-021-05520-z\", pubmed_id= '33757553',\n",
    "                    title='16S rRNA sequencing of samples from universal stool bank donors',\n",
    "                    status=OntologyAnnotation(term=\"indexed in PubMed\"),\n",
    "                    author_list=\"Marina Santiago, Scott W. Olesen\")],\n",
    "    factors = None, \n",
    "    protocols = None,\n",
    "    assays = None,\n",
    "    sources = None,\n",
    "    samples = None,\n",
    "    process_sequence = None,\n",
    "    other_material = None,\n",
    "    characteristic_categories = None,\n",
    "    comments = None,\n",
    "    units = None)\n",
    "investigation.studies.append(cohort_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:19:53.640383Z",
     "start_time": "2023-05-11T09:19:53.632319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define protocol parameters \n",
    "\n",
    "# Discuss what the parameters are of this project, can comment protocol_params out and leave the one you are sure of. Just to check if generating the files works. \n",
    "\n",
    "protocol_params = {\n",
    "    \"Metadata\": ProtocolParameter(\n",
    "        parameter_name = OntologyAnnotation(\n",
    "            term = \"Metadata\",\n",
    "            term_source = ontologies[\"NCIT\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/NCIT_C52095\")\n",
    "        ),\n",
    "\n",
    "    \"16s RNA sequence data\": ProtocolParameter(\n",
    "        parameter_name = OntologyAnnotation(\n",
    "            term = \"16s RNA sequence data\",\n",
    "            term_source = ontologies[\"NGBO\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/NGBO_6000204 \")\n",
    "        ),\n",
    "\n",
    "    \"low-input metagenomic next-generation sequencing\": ProtocolParameter(\n",
    "        parameter_name = OntologyAnnotation(\n",
    "            term = \"low-input metagenomic next-generation sequencing\",\n",
    "            term_source = ontologies[\"COVOC\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/COVOC_0010015\")\n",
    "        ),\n",
    "\n",
    "    \"adapter-sequence trimming\": ProtocolParameter(\n",
    "        parameter_name = OntologyAnnotation(\n",
    "            term = \"adapter-sequence trimming\",\n",
    "            term_source = ontologies[\"OBI\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/OBI_0002565 \")\n",
    "        ),\n",
    "\n",
    "    \"PCR primers\": ProtocolParameter(\n",
    "        parameter_name = OntologyAnnotation(\n",
    "            term = \"PCR primers\",\n",
    "            term_source = ontologies[\"EDAM\"],\n",
    "            term_accession = \"http://edamontology.org/data_1240 \")\n",
    "        ),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:19:56.603371Z",
     "start_time": "2023-05-11T09:19:56.593910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Assays\n",
    "\n",
    "assays = {\n",
    "    \"metataxonomics\": Assay(\n",
    "        filename = \"a_assay_metataxonomics.txt\",\n",
    "        measurement_type = OntologyAnnotation(\n",
    "            term = \"microbiome sequencing assay\",\n",
    "            term_source = ontologies[\"GECKO\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/GECKO_0000040\"),\n",
    "\n",
    "        technology_type = OntologyAnnotation(\n",
    "            term = \"microbiome sequencing assay\",\n",
    "            term_source = ontologies[\"GECKO\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/GECKO_0000040\")\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:20:00.044002Z",
     "start_time": "2023-05-11T09:20:00.037637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define protocols\n",
    "\n",
    "# Discuss what the parameters are of this project, can comment protocol_params out and leave the one you are sure of. Just to check if generating the files works. \n",
    "# The protocol_params only work if they are mentioned in define protocol parameters.\n",
    "\n",
    "protocols = {\n",
    "    \n",
    "    \"sample_collection\": Protocol( \n",
    "        name = \"material sampling process\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"material sampling process\",\n",
    "            term_source = ontologies[\"OBI\"],  \n",
    "            term_accession = \"http://purl.obolibrary.org/obo/OBI_0000744\"),\n",
    "        description = \"A specimen gathering process with the objective to obtain a specimen that is representative of the input material entity\",\n",
    "        parameters =[protocol_params[\"Metadata\"], protocol_params[\"16s RNA sequence data\"], protocol_params[\"low-input metagenomic next-generation sequencing\"]]\n",
    "        ),\n",
    "        \n",
    "    \"Data transformation\": Protocol(\n",
    "        name = \"Data transformation\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"data transformation\",\n",
    "            term_source = ontologies[\"OBI\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/OBI_0200000\"),\n",
    "        description = \"A planned process that produces output data from input data.\"\n",
    "        ),\n",
    "    \n",
    "    \"Polymerase Chain Reaction\": Protocol(\n",
    "        name = \"Polymerase Chain Reaction\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"Polymerase Chain Reaction\",\n",
    "            term_source = ontologies[\"NCIT\"],\n",
    "            term_accession = \"http://purl.obolibrary.org/obo/NCIT_C17003\"),\n",
    "        parameters = [protocol_params[\"PCR primers\"]]\n",
    "        ),\n",
    "       \n",
    "    \"operational taxonomic unit matrix\": Protocol( \n",
    "        name = \"operational taxonomic unit matrix\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"operational taxonomic unit matrix\",\n",
    "            term_source = ontologies[\"OBI\"],  \n",
    "            term_accession = \"http://purl.obolibrary.org/obo/OBI_0001968\"),\n",
    "        description = \"Operational Taxonomic Unit matrix is a data item, organized as a table, where organismal taxonomic units, computed by sequence analysis and genetic distance calculation, are counted in a set of biological or environmental samples. The table is used to appraise biodiversity of a population or community of living organism.\",\n",
    "        ),\n",
    "\n",
    "    \"demultiplexed sequence data\": Protocol( \n",
    "        name = \"demultiplexed sequence data\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"demultiplexed sequence data\",\n",
    "            term_source = ontologies[\"OBI\"],  \n",
    "            term_accession = \"http://purl.obolibrary.org/obo/OBI_0002601\"),\n",
    "        description = \"Sequence data in which an identifier subsequence has been used to categorize each reads by source.\",\n",
    "        ),\n",
    "\n",
    "    \"Quality Control\": Protocol( \n",
    "        name = \"Quality Control\",\n",
    "        protocol_type = OntologyAnnotation(\n",
    "            term = \"Quality Control\",\n",
    "            term_source = ontologies[\"NCIT\"],  \n",
    "            term_accession = \"http://purl.obolibrary.org/obo/NCIT_C15311 \"),\n",
    "        description = \"Set of measurements and inspections taken to verify that performance of equipment and procedures remains within specified limits.\",\n",
    "        ),\n",
    "\n",
    "}\n",
    "\n",
    "# append to study protocols\n",
    "for protocol in protocols.values():\n",
    "    cohort_study.protocols.append(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T09:20:04.578222Z",
     "start_time": "2023-05-11T09:20:04.280734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changed the Characteristics to the need of my metadata, removed some and deleted some. The phenotype is the SUBJECT-ID of the metadata. Changed the blood samples into stool samples.\n",
    "\n",
    "# add samples\n",
    "for index, row in patient_metadata.iterrows():\n",
    "    \n",
    "    # create source (=individual)\n",
    "    source_name = row[\"SUBJECT-ID\"]\n",
    "    source = Source(\n",
    "        name = source_name,\n",
    "        characteristics = [\n",
    "            Characteristic(\n",
    "                category = OntologyAnnotation(\n",
    "                    term = \"Organism\",\n",
    "                    term_source = ontologies[\"OBI\"],\n",
    "                    term_accession = \"http://purl.obolibrary.org/obo/OBI_0100026\"),\n",
    "                value = OntologyAnnotation(\n",
    "                    term = \"Homo sapiens\",\n",
    "                    term_source = ontologies[\"NCBITAXON\"],\n",
    "                    term_accession = \"http://purl.obolibrary.org/obo/NCBITaxon_9606\"))])\n",
    "     \n",
    "    \n",
    "    # Iterate over phenotype information (and add if available)\n",
    "    for meta_index, meta_row in patient_metadata.iterrows():\n",
    "        if source_name == meta_row[\"SUBJECT-ID\"]:\n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Subject Identifier\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C83083\"),\n",
    "                    value = meta_row[\"SUBJECT-ID\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Sex\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C28421\"),\n",
    "                    value = meta_row[\"GENDER\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Age-Years\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C37908\"),\n",
    "                    value = meta_row[\"AGE_(Y)\"]))\n",
    "        \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Body Mass Index)\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C16358\"),\n",
    "                    value = meta_row[\"BMI\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Body Height\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C164634\"),\n",
    "                    value = meta_row[\"HEIGHT_(CM)\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Body Weight\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C81328\"),\n",
    "                    value = meta_row[\"WEIGHT_(KG)\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Dietary Supplement\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C1505\"),\n",
    "                    value = meta_row[\"DIETARY_SUPPLEMENTS\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Probiotics\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C93144\"),\n",
    "                    value = meta_row[\"PROBIOTICS\"]))\n",
    "            \n",
    "            source.characteristics.append(\n",
    "                Characteristic(\n",
    "                    category = OntologyAnnotation(\n",
    "                        term = \"Diet\",\n",
    "                        term_source = ontologies['NCIT'],\n",
    "                        term_accession = \"http://purl.obolibrary.org/obo/NCIT_C15222 \"),\n",
    "                    value = meta_row[\"DIET\"]))\n",
    "    \n",
    "    # create sample\n",
    "    sample_name = row[\"SAMPLE-ID\"]\n",
    "    stool_sample = Sample(\n",
    "        name = sample_name, \n",
    "        derives_from = [source])\n",
    "    stool_sample.characteristics.append(\n",
    "        Characteristic(\n",
    "            category = OntologyAnnotation(\n",
    "                term = \"anatomical entity\",\n",
    "                term_source = ontologies[\"UBERON\"],\n",
    "                term_accession = \"http://purl.obolibrary.org/obo/UBERON_0001062\"),\n",
    "                ))\n",
    "    cohort_study.samples.append(stool_sample)\n",
    "    \n",
    "    # Sample collection_process                \n",
    "    sample_collection_process = Process(\n",
    "        name = \"samplecollection_{0}\".format(row[\"SUBJECT-ID\"]),\n",
    "        executes_protocol = protocols[\"sample_collection\"],\n",
    "        inputs = [source],\n",
    "        outputs = [stool_sample])\n",
    "    cohort_study.process_sequence.append(sample_collection_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add samples to metataxonomics assay\n",
    "\n",
    "# metataxonomics subdirectory\n",
    "metataxonomics_dir = os.path.join(working_directory)\n",
    "\n",
    "# Datafiles (not all are available)\n",
    "raw_datafile = DataFile(filename= \"blank\", label = \"Raw Spectral Data File\")\n",
    "normalized_datafile = DataFile(filename= \"\", label = \"Normalization Name\")\n",
    "derived_spectral_datafile = DataFile(filename= \"\", label = \"Derived Spectral Data File\")\n",
    "metadata_file = DataFile(filename=\"/Users/christelvanharen/Documents/StageRadboud/isatools/TWOCdemonstrator/data/ISA_test/metadata.tsv\", label = \"Patient metadata\")\n",
    "\n",
    "\n",
    "# Iterate over samples in study\n",
    "for index, row in patient_metadata.iterrows():\n",
    "    for idx, sample in enumerate(cohort_study.samples):\n",
    "\n",
    "        # Commented the row below out, this column doesn't exist in the dataset available.\n",
    "        if sample.name == row[\"SAMPLE-ID\"]:\n",
    "\n",
    "            # samples\n",
    "            material_extract = Material(\n",
    "                        name = \"extract_{0}\".format(sample.name),\n",
    "                        type_ = \"Extract Name\",\n",
    "                    )\n",
    "            \n",
    "            sequencing_extract = ParameterValue(\n",
    "                        category = protocol_params[\"16s RNA sequence data\"],\n",
    "                        value = \"16s RNA sequence data\"\n",
    "            )\n",
    "\n",
    "            metadata = ParameterValue(\n",
    "                        category = protocol_params[\"Metadata\"], \n",
    "                        value = \"\"\n",
    "                    )\n",
    "\n",
    "            extraction_process = Process(\n",
    "                        executes_protocol = protocols[\"sample_collection\"],\n",
    "                        parameter_values=[patient_metadata, sequencing_extract, metadata],\n",
    "                        inputs = [sample],\n",
    "                        outputs = [material_extract, metadata_file]\n",
    "                    )\n",
    "\n",
    "            ## Data transformation\n",
    "            data_transformation_process = Process(\n",
    "                        name = \"data_transformation_{0}\".format(sample.name),\n",
    "                        executes_protocol = protocols[\"Data transformation\"],\n",
    "                        inputs = [raw_datafile],\n",
    "                        outputs = [metadata_file, normalized_datafile, derived_spectral_datafile]  \n",
    "                    )\n",
    "\n",
    "            # Link processes, is for linking the processes to each other\n",
    "            plink(extraction_process, data_transformation_process)\n",
    "\n",
    "\n",
    "            # Add samples, materials and data files to the amines assay\n",
    "            assays[\"metataxonomics\"].samples.append(stool_sample)\n",
    "            assays[\"metataxonomics\"].other_material.append(material_extract)\n",
    "            assays[\"metataxonomics\"].data_files.append(raw_datafile)\n",
    "            assays[\"metataxonomics\"].data_files.append(normalized_datafile)\n",
    "            assays[\"metataxonomics\"].data_files.append(derived_spectral_datafile)\n",
    "            assays[\"metataxonomics\"].data_files.append(metadata_file)\n",
    "\n",
    "\n",
    "            ## Add processes to the amines assay\n",
    "            assays[\"metataxonomics\"].process_sequence.append(extraction_process)\n",
    "            assays[\"metataxonomics\"].process_sequence.append(data_transformation_process)\n",
    "\n",
    "# Add assays to cohort study\n",
    "# for assay in assays.values():\n",
    "#         cohort_study.assays.append(assay)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write ISA-Tab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 11:01:46,315 [INFO]: graph.py(_all_end_to_end_paths:20) >> [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309, 312, 315, 318, 321, 324, 327, 330, 333, 336, 339, 342, 345, 348, 351, 354, 357, 360, 363, 366]\n",
      "2023-05-30 11:01:46,316 [WARNING]: write.py(write_study_table_files:62) >> [2, 1, 0, 5, 4, 3, 8, 7, 6, 11, 10, 9, 14, 13, 12, 17, 16, 15, 20, 19, 18, 23, 22, 21, 26, 25, 24, 29, 28, 27, 32, 31, 30, 35, 34, 33, 38, 37, 36, 41, 40, 39, 44, 43, 42, 47, 46, 45, 50, 49, 48, 53, 52, 51, 56, 55, 54, 59, 58, 57, 62, 61, 60, 65, 64, 63, 68, 67, 66, 71, 70, 69, 74, 73, 72, 77, 76, 75, 80, 79, 78, 83, 82, 81, 86, 85, 84, 89, 88, 87, 92, 91, 90, 95, 94, 93, 98, 97, 96, 101, 100, 99, 104, 103, 102, 107, 106, 105, 110, 109, 108, 113, 112, 111, 116, 115, 114, 119, 118, 117, 122, 121, 120, 125, 124, 123, 128, 127, 126, 131, 130, 129, 134, 133, 132, 137, 136, 135, 140, 139, 138, 143, 142, 141, 146, 145, 144, 149, 148, 147, 152, 151, 150, 155, 154, 153, 158, 157, 156, 161, 160, 159, 164, 163, 162, 167, 166, 165, 170, 169, 168, 173, 172, 171, 176, 175, 174, 179, 178, 177, 182, 181, 180, 185, 184, 183, 188, 187, 186, 191, 190, 189, 194, 193, 192, 197, 196, 195, 200, 199, 198, 203, 202, 201, 206, 205, 204, 209, 208, 207, 212, 211, 210, 215, 214, 213, 218, 217, 216, 221, 220, 219, 224, 223, 222, 227, 226, 225, 230, 229, 228, 233, 232, 231, 236, 235, 234, 239, 238, 237, 242, 241, 240, 245, 244, 243, 248, 247, 246, 251, 250, 249, 254, 253, 252, 257, 256, 255, 260, 259, 258, 263, 262, 261, 266, 265, 264, 269, 268, 267, 272, 271, 270, 275, 274, 273, 278, 277, 276, 281, 280, 279, 284, 283, 282, 287, 286, 285, 290, 289, 288, 293, 292, 291, 296, 295, 294, 299, 298, 297, 302, 301, 300, 305, 304, 303, 308, 307, 306, 311, 310, 309, 314, 313, 312, 317, 316, 315, 320, 319, 318, 323, 322, 321, 326, 325, 324, 329, 328, 327, 332, 331, 330, 335, 334, 333, 338, 337, 336, 341, 340, 339, 344, 343, 342, 347, 346, 345, 350, 349, 348, 353, 352, 351, 356, 355, 354, 359, 358, 357, 362, 361, 360, 365, 364, 363, 368, 367, 366]\n",
      "2023-05-30 11:01:46,317 [INFO]: graph.py(_longest_path_and_attrs:64) >> [[0, 2, 1], [3, 5, 4], [6, 8, 7], [9, 11, 10], [12, 14, 13], [15, 17, 16], [18, 20, 19], [21, 23, 22], [24, 26, 25], [27, 29, 28], [30, 32, 31], [33, 35, 34], [36, 38, 37], [39, 41, 40], [42, 44, 43], [45, 47, 46], [48, 50, 49], [51, 53, 52], [54, 56, 55], [57, 59, 58], [60, 62, 61], [63, 65, 64], [66, 68, 67], [69, 71, 70], [72, 74, 73], [75, 77, 76], [78, 80, 79], [81, 83, 82], [84, 86, 85], [87, 89, 88], [90, 92, 91], [93, 95, 94], [96, 98, 97], [99, 101, 100], [102, 104, 103], [105, 107, 106], [108, 110, 109], [111, 113, 112], [114, 116, 115], [117, 119, 118], [120, 122, 121], [123, 125, 124], [126, 128, 127], [129, 131, 130], [132, 134, 133], [135, 137, 136], [138, 140, 139], [141, 143, 142], [144, 146, 145], [147, 149, 148], [150, 152, 151], [153, 155, 154], [156, 158, 157], [159, 161, 160], [162, 164, 163], [165, 167, 166], [168, 170, 169], [171, 173, 172], [174, 176, 175], [177, 179, 178], [180, 182, 181], [183, 185, 184], [186, 188, 187], [189, 191, 190], [192, 194, 193], [195, 197, 196], [198, 200, 199], [201, 203, 202], [204, 206, 205], [207, 209, 208], [210, 212, 211], [213, 215, 214], [216, 218, 217], [219, 221, 220], [222, 224, 223], [225, 227, 226], [228, 230, 229], [231, 233, 232], [234, 236, 235], [237, 239, 238], [240, 242, 241], [243, 245, 244], [246, 248, 247], [249, 251, 250], [252, 254, 253], [255, 257, 256], [258, 260, 259], [261, 263, 262], [264, 266, 265], [267, 269, 268], [270, 272, 271], [273, 275, 274], [276, 278, 277], [279, 281, 280], [282, 284, 283], [285, 287, 286], [288, 290, 289], [291, 293, 292], [294, 296, 295], [297, 299, 298], [300, 302, 301], [303, 305, 304], [306, 308, 307], [309, 311, 310], [312, 314, 313], [315, 317, 316], [318, 320, 319], [321, 323, 322], [324, 326, 325], [327, 329, 328], [330, 332, 331], [333, 335, 334], [336, 338, 337], [339, 341, 340], [342, 344, 343], [345, 347, 346], [348, 350, 349], [351, 353, 352], [354, 356, 355], [357, 359, 358], [360, 362, 361], [363, 365, 364], [366, 368, 367]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write to ISA-Tab\n",
    "from isatools import isatab\n",
    "isatab.dump(investigation, working_directory)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to ISA-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "with open(os.path.join(working_directory, \"isa.json\"), \"w\") as out_file:\n",
    "    # print(working_directory)\n",
    "    # print(investigation)\n",
    "    # print(out_file)\n",
    "    json.dump(\n",
    "        investigation, \n",
    "        out_file,\n",
    "        cls = ISAJSONEncoder, \n",
    "        sort_keys = True, \n",
    "        indent = 4, \n",
    "        separators = (',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isatool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "378e1b4d2575763aa25a90db8169ff98210cfa80085f31d2bda9db8d2252db8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
